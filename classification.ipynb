{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINO APIの基礎を学ぶ\n",
    "ここではシンプルな画像分類(Classification)プログラムを実行しながらOpenVINO Python APIの基礎を学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力画像とラベルデータの準備\n",
    "まずは推論に使用する入力画像ファイルと、クラスラベルのテキストファイルをOpenVINOのdemoディレクトリからコピーしてきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/car.png .\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/squeezenet1.1.labels synset_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!echo %INTEL_OPENVINO_DIR%\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\car.png\" .\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\squeezenet1.1.labels\" synset_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コピーしてきた推論入力の絵を表示して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('car.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論に使用するIRモデルデータの準備\n",
    "推論に使用するモデルを`Model downloader`でダウンロードし、`Model converter`でIRモデルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux  \n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/open_model_zoo/tools/downloader/downloader.py --name googlenet-v3\n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/open_model_zoo/tools/downloader/converter.py  --name googlenet-v3 --precisions FP16\n",
    "!ls public/googlenet-v3/FP16 -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows  \n",
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\open_model_zoo\\tools\\downloader\\downloader.py\" --name googlenet-v3 \n",
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\open_model_zoo\\tools\\downloader\\converter.py\"  --name googlenet-v3 --precisions FP16\n",
    "!dir public\\googlenet-v3\\FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "ここからPythonプログラム本体となります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プログラムで使用するモジュールをインポートする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスラベルテキストデータを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [ s.replace('\\n', '') for s in open('synset_words.txt').readlines() ]\n",
    "\n",
    "print(len(label), 'labels read')   # 読み込んだラベルの個数を表示\n",
    "print(label[:20])                  # ラベルの先頭の20個を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Engineオブジェクトを生成する\n",
    "- Inference Engineコアオブジェクトを生成\n",
    "- モデルデータの読み込み\n",
    "- 入出力ブロブ(バッファ)の情報取得  \n",
    "\n",
    "もちろんモデルの入出力ブロブ名やシェイプが既知の場合、わざわざモデルデータから取得せずにハードコードしてしまっても構いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Engineコアオブジェクトの生成\n",
    "ie = IECore()\n",
    "\n",
    "# IRモデルファイルの読み込み\n",
    "model = './public/googlenet-v3/FP16/googlenet-v3'\n",
    "net = ie.read_network(model=model+'.xml', weights=model+'.bin')\n",
    "\n",
    "# 入出力blobの名前の取得、入力blobのシェイプの取得\n",
    "input_blob_name  = list(net.input_info.keys())[0]\n",
    "output_blob_name = list(net.outputs.keys())[0]\n",
    "batch,channel,height,width = net.input_info[input_blob_name].tensor_desc.dims\n",
    "\n",
    "# モデルの情報の表示\n",
    "print(input_blob_name, batch, channel, height, width)\n",
    "print(output_blob_name, net.outputs[output_blob_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルをIE coreオブジェクトにロードする\n",
    "読み込んだネットワークオブジェクトをInference engineプラグインにセットします。  \n",
    "ここでは推論実行デバイスとして`CPU`を指定していますが、`'GPU'`, `'MYRIAD'`, `'HETERO:FPGA,CPU'`などを指定することでほかのデバイスを指定することも可能です。  \n",
    "OpenVINOを使ったアプリケーションではほとんどの場合この部分を書き換えるだけで簡単に推論実行デバイスを切り替えることが可能です。  \n",
    "\n",
    "**Note**: DevCloudの開発サーバーはCPUしか持っていません。その他のデバイスを試す場合は、DevCloudのedge computing nodeを使用する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_net = ie.load_network(network=net, device_name='CPU', num_requests=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論入力データを準備する\n",
    "推論入力画像を読み込み、入力ブロブのシェイプに合わせて変形します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('input blob: name=\"{}\", N={}, C={}, H={}, W={}'.format(input_blob_name, batch, channel, height, width))\n",
    "img = cv2.imread('car.png')\n",
    "img = cv2.resize(img, (width,height))\n",
    "img = img.transpose((2, 0, 1))\n",
    "img = img.reshape((1, channel, height, width))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論を実行する  \n",
    "`infer()` APIはブロッキング関数です。推論が終了すると制御が戻り、次の行を実行します。  \n",
    "入力は`{入力blob名:入力データ}`の辞書の形で渡します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = exec_net.infer(inputs={input_blob_name: img})\n",
    "\n",
    "print(res[output_blob_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論結果を表示する \n",
    "今回使用しているgooglenet-v3モデルは1000のクラスを持つImageNetデータセットで学習しています。1000のクラスごとの確率をFP32の数値で出力します。つまり推論結果は1000の要素を持つFloatの配列です。  \n",
    "推論結果をソートし、確率の高い順に5つ候補を表示させています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=res[output_blob_name][0]\n",
    "idx = np.argsort(result)[::-1]\n",
    "for i in range(5):\n",
    "    print(idx[i], result[idx[i]], label[idx[i]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "ここまでで一番シンプルな画像分類のプログラムの構成について学びました。  \n",
    "OpenVINO APIはシンプルに作られているので20行程度のPythonプログラムでディープラーニングを使った画像分類が可能です。  \n",
    "入力画像をいろいろ変えてみたりして実験してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next => OpenVINOを使った物体検出プログラムの基礎 - [object-detection-ssd.ipynb](./object-detection-ssd.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "interpreter": {
   "hash": "c9449627750e98e9b1ad30fb225936bb035c6d0e9c862047946b304a9e5cb973"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}