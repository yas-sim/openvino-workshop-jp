{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVINOを使ったC++プロジェクトを作る方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、OpenVINOを使った簡単な画像識別(classification)アプリケーションをC++で作成する方法、実行する方法について学びます。\n",
    "- OpenVINO C++プロジェクトの作り方、ビルド方法 (CMake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Windowsでビルドする場合\n",
    "OpenVINOパッケージに加えていくつかのソフトウエアをインストールする必要があります。  \n",
    "- Visual Studio (2019, C++)\n",
    "- CMake (x64用)\n",
    "- Python 3.7+ (x64)\n",
    "\n",
    "また、Visual Studioのツール類へのパスを通すため、スタートメニューから「Visual Studio 2019 / x64 Native Tools Command Prompt」でコマンドプロンプトを開き、そこからJupyterを起動してください。通常のコマンドプロンプト(cmd.exe)からJupyterを開くとパスが通っていないためビルドに失敗します。  \n",
    "ビルドにはIntel oneAPI base tool kitのDPC++ compiler (Data Parallel C++)も使用可能ですがここではその手順の紹介はしていません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 1. C++プログラムをビルドし、実行する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. DLモデルの準備\n",
    "OpenVINOを使った推論プログラムで利用するIRモデル(DLモデル)を準備します。今回のプログラムは画像の分類(classification)ですので、それに合うモデルをダウンロードします。ここでは`squeezenet1.1`モデルを使用します。  \n",
    "ここではモデルのダウンロードにはOpenVINO付属の`Model downloder`を、モデルをIRモデルに変換するのには`Model converter`を使用しています。実行ログの最後のほうに`[ SUCCESS ]`  と5つ表示されればIRモデルへの変換が完了です。変換されたIRモデルは`./public/squeezenet1.1/FP16/`の中に格納されています。\n",
    "\n",
    "**Memo:** 通常、TensorFlow, ONNX, CaffeなどのモデルデータをIRモデルデータに変換するには`Model optimizer`を使用します。`Model converter`は便利なツールですが、`Model downloader`でダウンロードしてきたモデルにしか使えません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/downloader.py --name squeezenet1.1\n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/converter.py  --name squeezenet1.1 --precisions FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\tools\\model_downloader\\downloader.py\" --name squeezenet1.1\n",
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\tools\\model_downloader\\converter.py\"  --name squeezenet1.1 --precisions FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. 推論に使用する入力画像とクラスラベルデータを準備する\n",
    "- 入力画像\n",
    " -- OpenVINOのデモプログラム実行テスト用の画像ファイルをコピーしてきます(`car.png`)\n",
    "- クラスラベルデータ\n",
    " -- 今回の`squeezenet1.1`モデルはImageNetのデータセットで学習されたモデルですので、画像を1000のクラスに分類します\n",
    " -- プログラムでクラス番号だけを表示しても意味が分からないので、ラベルテキストデータ(`synset_words.txt`)をOpenVINOサンプルディレクトリからコピーしクラス名を表示できるようにします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像データをコピー\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/car.png .\n",
    "# クラスラベルテキストデータをコピー\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/squeezenet1.1.labels synset_words.txt\n",
    "\n",
    "from IPython.display import Image\n",
    "Image('car.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows - 入力画像データをコピー\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\car.png\" .\n",
    "# クラスラベルテキストデータをコピー\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\squeezenet1.1.labels\" synset_words.txt\n",
    "\n",
    "from IPython.display import Image\n",
    "Image('car.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. C++ソースコードを用意する\n",
    "ここではワークショップの便宜上`%%writefile`マジックコマンドでソースコードファイルを生成していますが、テキストエディタなど他の手段でも問題ありません(むしろそちらの方が普通でしょう)。ここでは`main.cpp`という名前でソースファイルを用意しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile main.cpp\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <vector>\n",
    "\n",
    "#include <opencv2/opencv.hpp>\n",
    "#include <inference_engine.hpp>\n",
    "\n",
    "namespace ie = InferenceEngine;\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "\n",
    "    std::ifstream label_file(\"synset_words.txt\");  \n",
    "    std::string str;\n",
    "    std::vector<std::string> labels;\n",
    "    while(getline(label_file, str)) labels.push_back(str);\n",
    "    label_file.close();\n",
    "\n",
    "    // Creating an Inference Engine core object\n",
    "    ie::Core ie;\n",
    "\n",
    "    // Loading a DL model to memory\n",
    "    ie::CNNNetwork network = ie.ReadNetwork(\"public/squeezenet1.1/FP16/squeezenet1.1.xml\",\n",
    "                                            \"public/squeezenet1.1/FP16/squeezenet1.1.bin\");\n",
    "    // Setting up the input blob\n",
    "    std::shared_ptr<ie::InputInfo> input_info = network.getInputsInfo().begin()->second;\n",
    "    std::string input_name = network.getInputsInfo().begin()->first;\n",
    "    input_info->getPreProcess().setResizeAlgorithm(ie::RESIZE_BILINEAR);\n",
    "    input_info->setLayout(ie::Layout::NHWC);\n",
    "    input_info->setPrecision(ie::Precision::U8);\n",
    "\n",
    "    // Setting up the output blob\n",
    "    ie::DataPtr output_info = network.getOutputsInfo().begin()->second;\n",
    "    std::string output_name = network.getOutputsInfo().begin()->first;\n",
    "    output_info->setPrecision(ie::Precision::FP32);\n",
    "\n",
    "    // Set the DL model to an Inference Engine object\n",
    "    ie::ExecutableNetwork executable_network = ie.LoadNetwork(network, \"CPU\");\n",
    "    ie::InferRequest infer_request = executable_network.CreateInferRequest();\n",
    "\n",
    "// main inferencing loop - start -------\n",
    "\n",
    "    cv::Mat image = cv::imread(\"car.png\");   // Loading an image\n",
    "\n",
    "    ie::TensorDesc tDesc(ie::Precision::U8, \n",
    "        {1, 3, static_cast<long unsigned int>(image.rows), \n",
    "               static_cast<long unsigned int>(image.cols) }, ie::Layout::NHWC);\n",
    "    infer_request.SetBlob(input_name, ie::make_shared_blob<uint8_t>(tDesc, image.data));\n",
    "\n",
    "    infer_request.Infer();                   // Do inferencing\n",
    "\n",
    "    // Displaying result\n",
    "    float* output = infer_request.GetBlob(output_name)->buffer();\n",
    "    std::cout << \"\\nresults\\n------------------\" << std::endl;\n",
    "    std::vector<int> idx;\n",
    "    for(int i=0; i<1000; i++) idx.push_back(i);\n",
    "    std::sort(idx.begin(), idx.end(), [output](const int& left, const int& right) { return output[left]>output[right]; } );\n",
    "    for (size_t id = 0; id < 5; ++id)  std::cout << id <<  \" : \" << idx[id] << \" : \" << \n",
    "        std::fixed<< std::setprecision(2) << output[idx[id]]*100 << \"% \" << labels[idx[id]] << std::endl;\n",
    "\n",
    "// main inferencing loop - end ------\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. `CMakeLists.txt`を用意する\n",
    "ここでは`cmake`を使ってC++ソースのビルドを行いますので、そのための設定ファイル(`CMakeLists.txt`)を`%%writefile`コマンドで用意しています。  \n",
    "`set(TARGET_NAME`の部分と`add_executable(`の部分を書き換えれば、別のプロジェクトに流用できます。もちろん、追加のライブラリなどを利用する場合はそれらを`target_link_libraries(`に追加したり、`find_package(`を追加したりする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CMakeLists.txt\n",
    "# Sample CMakeLists.txt file for an OpenVINO Inference Engine project\n",
    "project(Project)\n",
    "cmake_minimum_required (VERSION 2.8.1)\n",
    "\n",
    "set(TARGET_NAME simple_cnn)     # name of executable file\n",
    "set(CMAKE_BUILD_TYPE \"Release\")\n",
    "\n",
    "set(CMAKE_CXX_STANDARD 11)\n",
    "set(CMAKE_CXX_STANDARD_REQUIRED ON)\n",
    "set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -fPIE\")\n",
    "\n",
    "find_package(InferenceEngine 1.1 REQUIRED)\n",
    "find_package(OpenCV REQUIRED)\n",
    "add_definitions(-DUSE_OPENCV)\n",
    "\n",
    "include_directories( ${InferenceEngine_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS} )\n",
    "link_directories( )\n",
    "\n",
    "add_executable( ${TARGET_NAME} main.cpp )    # list of source file(s)\n",
    "set_target_properties(${TARGET_NAME} PROPERTIES \"CMAKE_CXX_FLAGS\" \"${CMAKE_CXX_FLAGS}\")\n",
    "target_link_libraries(${TARGET_NAME} ${InferenceEngine_LIBRARIES} ${OpenCV_LIBS} )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. ビルドを行う\n",
    "`build`ディレクトリを作成しC++ソースをビルドします。  \n",
    "`!`コマンドは1行ごとにシェルを抜けてしまいますので、`cd`コマンドなどシェルの状態を変えるコマンドを発行しても現在の行の実行が終わるとともに状態が破棄されてしまいます(コマンドは子シェルで実行されます)。そのため、`&&`でコマンドをつなぎ、１行でビルドしています。  \n",
    "ビルドされた実行可能バイナリは`./build/simple_cnn` または`build\\Release\\simple_cnn.exe`です。\n",
    "Windowsの場合はVisual Studio 2019を使ってビルドすることを想定しています。ここではmsbuildコマンドを使ってコマンドラインビルドを行っていますが、cmakeが生成するProject.slnファイルをVisual Studioで開き、IDE上でビルドすることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "!mkdir -p build && cd build && cmake .. && make && ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!if not exist build (mkdir build)\n",
    "!cd build && cmake -G \"Visual Studio 16 2019\" .. && msbuild Project.sln /t:clean;rebuild /p:Configuration=Release;Platform=\"x64\" && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. ビルドしたプログラムを実行する\n",
    "ビルドしたexecutableを実行してみます。  \n",
    "このプログラムは引数を取りません。使用するファイル名(モデル名、入力画像ファイル名、クラスラベルファイル名)はプログラム中にハードコードされています。  \n",
    "ただしく推論結果が表示されることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "!build/simple_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!build\\Release\\simple_cnn.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "ここまででOpenVINOを使った簡単なC++プログラムをDevCloud上でビルド、実行する方法を学びました。  \n",
    "今回のプログラムを小改造していろいろ試したり、実行したりしてみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<おわり>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
