{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 非同期推論実行方法の基礎を学ぶ\n",
    "OpenVINOを使って効率の良い推論プログラムを作るには非同期推論(asynchronous inference)を活用するのが重要です。  \n",
    "同期推論(synchronous inference)で使用する`infer()` APIはブロッキング関数なので、プログラムは推論が終わるまで待たされてしまうので他の処理を同時に行うことができません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力画像とラベルデータの準備\n",
    "まずは推論に使用する入力画像ファイルと、クラスラベルのテキストファイルをOpenVINOのdemoディレクトリからコピーしてきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/car.png .\n",
    "!cp $INTEL_OPENVINO_DIR/deployment_tools/demo/squeezenet1.1.labels synset_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\car.png\" .\n",
    "!copy \"%INTEL_OPENVINO_DIR%\\deployment_tools\\demo\\squeezenet1.1.labels\" synset_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コピーしてきた推論入力の絵を表示して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('car.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論に使用するIRモデルデータの準備\n",
    "推論に使用するモデルを`Model downloader`でダウンロードし、`Model converter`でIRモデルに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linux\n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/downloader.py --name googlenet-v3\n",
    "!python3 $INTEL_OPENVINO_DIR/deployment_tools/tools/model_downloader/converter.py  --name googlenet-v3 --precisions FP16\n",
    "!ls public/googlenet-v3/FP16 -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows\n",
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\tools\\model_downloader\\downloader.py\" --name googlenet-v3\n",
    "!python \"%INTEL_OPENVINO_DIR%\\deployment_tools\\tools\\model_downloader\\converter.py\"  --name googlenet-v3 --precisions FP16\n",
    "!dir public\\googlenet-v3\\FP16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "ここからPythonプログラム本体となります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenVINOアプリケーションの初期化を行う\n",
    "この部分は前の画像分類プログラムと全く同じです。\n",
    "1. 必要なPythonモジュールをインポートする\n",
    "2. クラスラベルデータを読み込む\n",
    "3. Inference engineのcoreオフジェクトの生成\n",
    "4. IRモデルをメモリに読み込む\n",
    "5. Input / Outputブロブの情報の取得\n",
    "6. モデルをIE coreオブジェクトにロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "label = open('synset_words.txt').readlines()\n",
    "\n",
    "# Inference Engineコアオブジェクトの生成\n",
    "ie = IECore()\n",
    "\n",
    "# IRモデルファイルの読み込み\n",
    "model = './public/googlenet-v3/FP16/googlenet-v3'\n",
    "net = ie.read_network(model=model+'.xml', weights=model+'.bin')\n",
    "\n",
    "# 入出力blobの名前の取得、入力blobのシェイプの取得\n",
    "input_blob_name  = list(net.input_info.keys())[0]\n",
    "output_blob_name = list(net.outputs.keys())[0]\n",
    "batch,channel,height,width = net.input_info[input_blob_name].tensor_desc.dims\n",
    "\n",
    "exec_net = ie.load_network(network=net, device_name='CPU', num_requests=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コールバック関数をセットする\n",
    "コールバック関数にラムダ式(無名関数)を指定することも可能です。 \n",
    "`set_completion_callback()`関数の第２引数はユーザーデータで、コールバック関数に渡されます。ここでは`exec_net.requests[req_id]`を渡すことで、コールバック関数内で結果の表示ができるようにしています。\n",
    "コールバック関数の中では推論結果の表示をさせています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(status_code, infer_request):\n",
    "    output = infer_request.output_blobs[output_blob_name].buffer[0]\n",
    "    idx = np.argsort(output)[::-1]\n",
    "    for i in range(5):\n",
    "        print(idx[i], output[idx[i]], label[idx[i]-1][:-1])\n",
    "\n",
    "req_id=0\n",
    "exec_net.requests[req_id].set_completion_callback(callback, exec_net.requests[req_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論入力データを準備する\n",
    "推論入力画像を読み込み、入力ブロブのシェイプに合わせて変形します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('car.png')\n",
    "img = cv2.resize(img, (width,height))\n",
    "img = img.transpose((2, 0, 1))\n",
    "img = img.reshape((1, channel, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **非同期**推論を実行する  \n",
    "`start_async()` APIを実行すると実際の推論は別スレッドで実行され、すぐに制御が戻ってきます。メインスレッドでは0.1秒おきにインクリメントされた数字を表示する処理に移行しますが並行して推論スレッドが走っています。そのため、数字を表示する処理が開始されますが、その途中で推論が終わり、コールバック関数が呼ばれて推論結果が表示されるのがわかると思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = exec_net.start_async(0, inputs={input_blob_name: img})\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, flush=True)\n",
    "    time.sleep(0.1)    # 0.1秒待つ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## ここまでで非同期推論プログラムの作り方の基礎について学びました\n",
    "非同期推論を活用することでハードウエア資源を効率よく利用することが可能になります。  \n",
    "内蔵GPU, VPU (Myriad)などの推論デバイスを使用する際も、せっかく処理をCPUからオフロードしたのに外部デバイスの推論終了までCPUの処理が停止していては意味がありません。  \n",
    "非同期推論の使い方をぜひマスターして、効率よいOpenVINOアプリケーション作成を行ってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next => 非同期推論、同時推論を使った高スループットアプリケーションの基礎 - [classification-async-multi.ipynb](./classification-async-multi.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
